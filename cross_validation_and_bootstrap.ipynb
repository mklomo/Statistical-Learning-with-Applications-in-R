{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Validation Set Approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>392</li>\n",
       "\t<li>9</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 392\n",
       "\\item 9\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 392\n",
       "2. 9\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 392   9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ISLR2)\n",
    "\n",
    "set.seed(1)\n",
    "\n",
    "dim(Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subset of 196 observations out of the 392 observations\n",
    "train <- sample(392, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "23.2660086465003"
      ],
      "text/latex": [
       "23.2660086465003"
      ],
      "text/markdown": [
       "23.2660086465003"
      ],
      "text/plain": [
       "[1] 23.26601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the subset option and run a linear regression on the Auto data \n",
    "lm_fit <- lm(mpg ~ horsepower, data = Auto, subset = train)\n",
    "\n",
    "# Estimate the response for all 392 observations and use the mean function\n",
    "# to calculate the MSE of 196 observations in the validation set \n",
    "attach(Auto)\n",
    "\n",
    "mean((mpg - predict(lm_fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following objects are masked from Auto (pos = 3):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "18.7164594933828"
      ],
      "text/latex": [
       "18.7164594933828"
      ],
      "text/markdown": [
       "18.7164594933828"
      ],
      "text/plain": [
       "[1] 18.71646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can use the poly() function to estimate the \n",
    "# test error for the quadratic regressions.\n",
    "lm_fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)\n",
    "\n",
    "attach(Auto)\n",
    "mean((mpg - predict(lm_fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following objects are masked from Auto (pos = 3):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 4):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "18.7940067973945"
      ],
      "text/latex": [
       "18.7940067973945"
      ],
      "text/markdown": [
       "18.7940067973945"
      ],
      "text/plain": [
       "[1] 18.79401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can use the poly() function to estimate the \n",
    "# test error for the cubic regressions.\n",
    "lm_fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)\n",
    "\n",
    "attach(Auto)\n",
    "mean((mpg - predict(lm_fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following objects are masked from Auto (pos = 3):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 4):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 5):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "23.2660086465003"
      ],
      "text/latex": [
       "23.2660086465003"
      ],
      "text/markdown": [
       "23.2660086465003"
      ],
      "text/plain": [
       "[1] 23.26601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(2)\n",
    "\n",
    "\n",
    "# Use the subset option and run a linear regression on the Auto data \n",
    "lm_fit <- lm(mpg ~ horsepower, data = Auto, subset = train)\n",
    "\n",
    "# Estimate the response for all 392 observations and use the mean function\n",
    "# to calculate the MSE of 196 observations in the validation set \n",
    "attach(Auto)\n",
    "\n",
    "mean((mpg - predict(lm_fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following objects are masked from Auto (pos = 3):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 4):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 5):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 6):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 7):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 8):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "18.7164594933828"
      ],
      "text/latex": [
       "18.7164594933828"
      ],
      "text/markdown": [
       "18.7164594933828"
      ],
      "text/plain": [
       "[1] 18.71646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can use the poly() function to estimate the \n",
    "# test error for the quadratic regressions.\n",
    "lm_fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)\n",
    "\n",
    "attach(Auto)\n",
    "mean((mpg - predict(lm_fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following objects are masked from Auto (pos = 3):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 4):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 5):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 6):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 7):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 8):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n",
      "The following objects are masked from Auto (pos = 9):\n",
      "\n",
      "    acceleration, cylinders, displacement, horsepower, mpg, name,\n",
      "    origin, weight, year\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "18.7940067973945"
      ],
      "text/latex": [
       "18.7940067973945"
      ],
      "text/markdown": [
       "18.7940067973945"
      ],
      "text/plain": [
       "[1] 18.79401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can use the poly() function to estimate the \n",
    "# test error for the cubic regressions.\n",
    "lm_fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)\n",
    "\n",
    "attach(Auto)\n",
    "mean((mpg - predict(lm_fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross-Validation\n",
    "\n",
    "We will perform linear\n",
    "regression using the glm() function rather than the lm() function because\n",
    "the former can be used together with cv.glm(). The cv.glm() function is\n",
    "part of the boot library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2315135179292</li>\n",
       "\t<li>24.2311440937562</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 24.2311440937562\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 24.2311440937562\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 24.23114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(boot)\n",
    "\n",
    "glm_fit <- glm(mpg ~ horsepower, data = Auto)\n",
    "\n",
    "cv_err <- cv.glm(Auto, glm_fit)\n",
    "\n",
    "cv_err$delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cv.glm() function produces a list with several components. The two\n",
    "numbers in the delta vector contain the cross-validation results. In this\n",
    "case the numbers are identical (up to two decimal places) and correspond\n",
    "to the LOOCV statistic.\n",
    "\n",
    "Below, we discuss a situation in\n",
    "which the two numbers differ. Our cross-validation estimate for the test\n",
    "error is approximately 24.23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat this procedure for increasingly complex polynomial fits. To automate the process, we use the for() function to initiate a for loop which iteratively fits polynomial regressions for polynomials of order i = 1to i = 10, computes the associated cross-validation error, and stores it in the ith element of the vector cv.error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2315135179292</li>\n",
       "\t<li>19.2482131244897</li>\n",
       "\t<li>19.3349840640291</li>\n",
       "\t<li>19.4244303104302</li>\n",
       "\t<li>19.0332138547041</li>\n",
       "\t<li>18.9786436582254</li>\n",
       "\t<li>18.8330450653182</li>\n",
       "\t<li>18.9611507120531</li>\n",
       "\t<li>19.0686299814602</li>\n",
       "\t<li>19.4909322993293</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 19.2482131244897\n",
       "\\item 19.3349840640291\n",
       "\\item 19.4244303104302\n",
       "\\item 19.0332138547041\n",
       "\\item 18.9786436582254\n",
       "\\item 18.8330450653182\n",
       "\\item 18.9611507120531\n",
       "\\item 19.0686299814602\n",
       "\\item 19.4909322993293\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 19.2482131244897\n",
       "3. 19.3349840640291\n",
       "4. 19.4244303104302\n",
       "5. 19.0332138547041\n",
       "6. 18.9786436582254\n",
       "7. 18.8330450653182\n",
       "8. 18.9611507120531\n",
       "9. 19.0686299814602\n",
       "10. 19.4909322993293\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.23151 19.24821 19.33498 19.42443 19.03321 18.97864 18.83305 18.96115\n",
       " [9] 19.06863 19.49093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_error2 <- rep(0, 10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    glm_fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "    cv_error2[i] <- cv.glm(Auto, glm_fit)$delta[1]\n",
    "}\n",
    "\n",
    "cv_error2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Cross Validation\n",
    "\n",
    "The cv.glm() function can also be used to implement k-fold CV. Below we\n",
    "use k = 10, a common choice for k, on the Auto data set. We once again set\n",
    "a random seed and initialize a vector in which we will store the CV errors\n",
    "corresponding to the polynomial fits of orders one to ten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2720671232254</li>\n",
       "\t<li>19.2690928085129</li>\n",
       "\t<li>19.3480535605547</li>\n",
       "\t<li>19.2949648229745</li>\n",
       "\t<li>19.0319790002896</li>\n",
       "\t<li>18.8978121056401</li>\n",
       "\t<li>19.1206066690695</li>\n",
       "\t<li>19.1466631054789</li>\n",
       "\t<li>18.8701307442148</li>\n",
       "\t<li>20.9552042280389</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2720671232254\n",
       "\\item 19.2690928085129\n",
       "\\item 19.3480535605547\n",
       "\\item 19.2949648229745\n",
       "\\item 19.0319790002896\n",
       "\\item 18.8978121056401\n",
       "\\item 19.1206066690695\n",
       "\\item 19.1466631054789\n",
       "\\item 18.8701307442148\n",
       "\\item 20.9552042280389\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2720671232254\n",
       "2. 19.2690928085129\n",
       "3. 19.3480535605547\n",
       "4. 19.2949648229745\n",
       "5. 19.0319790002896\n",
       "6. 18.8978121056401\n",
       "7. 19.1206066690695\n",
       "8. 19.1466631054789\n",
       "9. 18.8701307442148\n",
       "10. 20.9552042280389\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.27207 19.26909 19.34805 19.29496 19.03198 18.89781 19.12061 19.14666\n",
       " [9] 18.87013 20.95520"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(17)\n",
    "\n",
    "cv_error10 <- rep(0, 10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    glm_fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "    cv_error10[i] <- cv.glm(Auto, glm_fit, K = 10)$delta[1]\n",
    "}\n",
    "\n",
    "cv_error10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bootstrap\n",
    "\n",
    "One of the great advantages of the bootstrap approach is that it can be\n",
    "applied in almost all situations. No complicated mathematical calculations\n",
    "are required. Performing a bootstrap analysis in R entails only two steps.\n",
    "First, we must create a function that computes the statistic of interest.\n",
    "Second, we use the boot() function, which is part of the boot library, to\n",
    "perform the bootstrap by repeatedly sampling observations from the data\n",
    "set with replacement.\n",
    "\n",
    "The bootstrap approach can be used to assess the variability of the coefficient\n",
    "estimates and predictions from a statistical learning method. Here\n",
    "we use the bootstrap approach in order to assess the variability of the\n",
    "estimates for β0 and β1, the intercept and slope terms for the linear regression\n",
    "model that uses horsepower to predict mpg in the Auto data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>39.9358610211705</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.157844733353654</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot_fn <- function(data, index) {\n",
    "\n",
    "    coef(lm(mpg ~ horsepower, data = data, subset = index))\n",
    "\n",
    "}\n",
    "\n",
    "boot_fn(data = Auto, index = 1:392)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boot.fn() function can also be used in order to create bootstrap estimates\n",
    "for the intercept and slope terms by randomly sampling from among\n",
    "the observations with replacement. Here we give two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>40.3404516830189</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.163486837689938</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 40.3404516830189\n",
       "\\item[horsepower] -0.163486837689938\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   40.3404516830189horsepower\n",
       ":   -0.163486837689938\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 40.3404517  -0.1634868 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "\n",
    "boot_fn(data = Auto, sample(392, 392, replace = T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot_fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "      original        bias    std. error\n",
       "t1* 39.9358610  0.0549915227 0.841925746\n",
       "t2* -0.1578447 -0.0006210818 0.007348956"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next, we use the boot() function to compute the standard errors of 1,000\n",
    "# bootstrap estimates for the intercept and slope terms.\n",
    "\n",
    "boot(Auto, boot_fn, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the bootstrap estimate for SE( ˆ β0) is 0.84, and that the bootstrap estimate for SE( ˆ β1) is 0.0073. Standard formulas can be used to compute the standard errors for the regression coefficients in a linear model. These can be obtained using the summary() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>39.9358610   </td><td>0.717498656  </td><td> 55.65984    </td><td>1.220362e-187</td></tr>\n",
       "\t<tr><th scope=row>horsepower</th><td>-0.1578447   </td><td>0.006445501  </td><td>-24.48914    </td><td> 7.031989e-81</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 39.9358610    & 0.717498656   &  55.65984     & 1.220362e-187\\\\\n",
       "\thorsepower & -0.1578447    & 0.006445501   & -24.48914     &  7.031989e-81\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | 39.9358610    | 0.717498656   |  55.65984     | 1.220362e-187 |\n",
       "| horsepower | -0.1578447    | 0.006445501   | -24.48914     |  7.031989e-81 |\n",
       "\n"
      ],
      "text/plain": [
       "            Estimate   Std. Error  t value   Pr(>|t|)     \n",
       "(Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187\n",
       "horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(mpg ~ horsepower, data = Auto))$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error estimates for ˆ β0 and ˆ β1 obtained using the formulas are 0.717 for the intercept and 0.0064 for the slope.\n",
    "Interestingly, these are somewhat different from the estimates obtained using the bootstrap. Does this indicate a problem with the bootstrap? Infact, it suggests the opposite. The coefficients from the summary function rely on 2 assumptions: \n",
    "- they depend on the unknown parameter σ2, the noise variance.We then estimate σ2 using the RSS. Now although the formulas for the standard errors do not rely on the linear model being correct, the estimate for σ2 does.\n",
    "\n",
    "- Secondly, the standard formulas assume (somewhat unrealistically) that the xi are fixed, and all the variability comes from the variation in the errors ϵi.\n",
    "\n",
    "\n",
    "The bootstrap approach does not rely on any of these assumptions, and so it is likely giving a more accurate estimate of the standard errors of ˆ β0 and ˆ β1 than is the summary() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot_fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "        original        bias     std. error\n",
       "t1* 56.900099702  3.511640e-02 2.0300222526\n",
       "t2* -0.466189630 -7.080834e-04 0.0324241984\n",
       "t3*  0.001230536  2.840324e-06 0.0001172164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = mpg ~ horsepower + I(horsepower^2), data = Auto)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-14.7135  -2.5943  -0.0859   2.2868  15.8961 \n",
       "\n",
       "Coefficients:\n",
       "                  Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)     56.9000997  1.8004268   31.60   <2e-16 ***\n",
       "horsepower      -0.4661896  0.0311246  -14.98   <2e-16 ***\n",
       "I(horsepower^2)  0.0012305  0.0001221   10.08   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 4.374 on 389 degrees of freedom\n",
       "Multiple R-squared:  0.6876,\tAdjusted R-squared:  0.686 \n",
       "F-statistic:   428 on 2 and 389 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Builing a finction for the Quadratic Model\n",
    "boot_fn <- function(data, index) {\n",
    "    coef(\n",
    "        lm(mpg ~ horsepower + I(horsepower^2), data = data, subset = index)\n",
    "    )\n",
    "}\n",
    "\n",
    "# Bootstrap estimates of the Coefficient Errors\n",
    "\n",
    "set.seed(1)\n",
    "\n",
    "boot(data = Auto, statistic = boot_fn, R = 1000)\n",
    "\n",
    "# Standard Error estimates with linear regression\n",
    "summary(lm(mpg ~ horsepower + I(horsepower^2), data = Auto))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "python397jvsc74a57bd015a99dc70f55bf54f5bf01a7bb523eaef6639a4e03a216c1285b710bbab4b128"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
